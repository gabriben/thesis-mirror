%!TEX root = ../main.tex

\section{Related Work}
\label{section:fact-related-work}

There have been multiple calls for introducing ethics in computer science courses in general, and in AI programs in particular \citep{leonelli2016locating, o2017ivory, singer2018tech, skirpan2018ethics, grosz2019embedded, salz2019integrating, danyluk2021computing}. 
Several surveys have investigated how existing responsible computing courses are organized \citep{peck2017,fiesler2020we, garret2020morethan, raji_you_2021}. 

\subsection{Characterizing Responsible AI Courses}
There are two primary approaches to integrating such components into the curriculum: 
\begin{enumerate*}[label=(\roman*)]
\item stand-alone courses that focus on ethical issues such as FACT-AI topics, and 
\item a holistic curriculum where ethical issues are introduced and tackled in each course. 
\end{enumerate*}
In general, the latter is rare \citep{peck2017, salz2019integrating, fiesler2020we}, and can be difficult to organize due to a lack of qualified faculty or relevant expertise \citep{bates2020integrating, raji_you_2021}. 
We opt for the first approach since our course is a new addition to an existing study program. 
%Since we were designing one new course to be added into an existing program, we opted for the first approach. 

\citet{fiesler2020we} analyze 202 courses on ``tech ethics''. 
Their survey examines 
\begin{enumerate*}[label=(\roman*)]
\item the departments the courses are taught from, as well as the home departments of the course instructors, 
\item the topics covered in the courses, organized into 15 categories, and 
\item the learning outcomes in the courses. 
\end{enumerate*}
In our case, both the FACT-AI course and its instructors are from the Informatics Institute of the Faculty of Science at \OurUniversity{}. Our learning objectives (see Section~\ref{section:learning-objectives}) correspond to the following learning objectives from \citet{fiesler2020we}: \textit{``Critique''}, \textit{``Spot Issues''}, and \textit{``Create solutions''}. 
According to their content topic categorization, our course includes \textit{``AI \& Algorithms''} and \textit{``Research Ethics''}: the former since the course deals explicitly with AI algorithms under the FACT-AI umbrella, and the latter due to its focus on reproducibility. 

We note that \textit{``AI \& Algorithms''} is only the fifth-most popular topic according to the survey, after \textit{``Law \& Policy''}, \textit{``Privacy \& Surveillance''}, \textit{``Philosophy''}, and \textit{``Inequality, Justice \& Human Rights''} \citep[see Table 2,][]{fiesler2020we}). 
Although we believe these topics are important, we also wanted to avoid the feeling that the course was a ``distraction from the real material'' \citep{lewis2021teaching}, especially since 
\begin{enumerate*}[label=(\roman*)]
\item the majority of our students are coming from a technical background into a technical MSc program, and 
\item the FACT-AI course is mandatory for all students in the MSc AI program. 
\end{enumerate*}

\subsection{Similar Responsible AI Courses}
The two courses that are the most similar to ours are those of \citet{lewis2021teaching} and \citet{yildiz2021reproducedpapers}. 

\citet{lewis2021teaching} describe a course for responsible data science. 
Similar to our course, they focus on the technical aspects of AI, involving lectures, readings, and a final project. 
However, their course differs from ours since the main project in their course is focused on examining the interpretability of an automated decision making system, while the main project in our course is focused on reproducibility. 

\citet{yildiz2021reproducedpapers} describe a course based on reproducing experiments from AI papers, focusing on ``low-barrier'' reproducibility. 
Similar to our course, this course involves replicating a paper from scratch or reproducing the experiments using existing code, performing hyperparameter sweeps, and testing with new data or with variant algorithms. 
Another similarity is that they released a public repository of re-implemented algorithms,\footnote{\url{https://reproducedpapers.org/}} which we also did for the 2019--2020 iteration of our course (see Section~\ref{section:assignment}). 
However, their course differs from ours since theirs focuses on AI papers in general, while our course focuses exclusively on FACT-AI papers. 

There are several courses that focus more on the philosophical or social science perspectives of AI ethics.
\citet{green2021aiethics} describes an undergraduate AI ethics course that teaches computer science majors to analyse issues using different ethical approaches and how to incorporate these into an \textit{explicit} ethical agent. 
\citet{shenvalue2021} introduce a toolkit in the form of ``Value Cards'' to inform students and practitioners about the social impacts of ML models through deliberation.
\citet{green2020argument} propose an approach to ethics education using ``argument schemes'' that summarize key ethical considerations for specialized domains such as healthcare or national defense.
\citet{Furey2018IntroducingET} introduce ethics concepts, primarily utilitarianism, into an existing AI course about autonomous vehicles by studying several variations of the Trolley Problem.  
\citet{burton2018} teach ethics through science fiction stories complemented with philosophy papers, allowing students to reflect and debate difficult content without emotional or personal investment since the stories are not tied to ``real'' issues. 
\citet{skirpan2018ethics} describe an undergraduate course on human-centred computing which integrates ethical thinking throughout the design of computational systems. 
Unlike these courses, our course focuses more on the technical aspects of ethical AI.  
However, incorporating such non-technical perspectives is something we would like to do in future iterations of our course, perhaps through one of the mechanisms employed by some of these courses. 

\section{Reproducibility in ML Research}
\label{section:reproducibility}

There have been several criticisms about the lack of reproducibility in AI research. 
Some have postulated that this is due to a combination of unpublished code and high sensitivity of training parameters \citep{hutson2018artificial}, while others believe the rapid rate of progress in ML research results in a lack of empirical rigor \citep{sculley2018winner}. 
Although typically well-intentioned, some papers may disguise speculation as explanation, obfuscate content behind math or language, and fail to attribute the correct sources of empirical gains \citep{lipton2019research}. 

Several efforts have been made to investigate and increase the reproducibility of AI research. 
In 2021, NeurIPS introduced a paper checklist including questions about reproducibility, along with a template for submitting source code as supplementary material \citep{neuripschecklist}. 
The Association of Computing Machinery introduced a badging system that indicates how reproducible a paper is \citep{acm-artifact}. 
Papers with Code is an organization that provides links to official code repositories and datasets in arXiv papers \citep{paperswithcode2020}. 
It also hosts an annual ML Reproducibility Challenge: a community-wide effort to investigate the reproducibility of papers accepted at top AI conferences, which we incorporated into the 2020--2021 iteration of the FACT-AI course. 

In an ideal scenario, reproducibility issues would be handled prior to publication \citep{sculley2018winner}, 
but it can be difficult to catch such shortcomings in the review process due to the increasing number of papers submitted to AI conferences. 
Therefore, we believe it is of utmost importance that the next generation of AI researchers -- including our own students -- can 
\begin{enumerate*}[label=(\roman*)]
\item identify and 
\item avoid these pitfalls while conducting their own work. 
\end{enumerate*}
This, in combination with the fact that reproducibility is a fundamental component of responsible AI research, is why we opted to teach the FACT-AI course through the lens of reproducibility. 

Our course is centered around a group project where students re-implement a recent FACT-AI algorithm from a top AI conference. 
This project has three components:
\begin{enumerate*}[label=(\roman*)]
\item a reproducibility report, 
\item an associated code base, and 
\item a group presentation. 
\end{enumerate*}
In Section~\ref{section:assignment}, we provide more details on the project and the outputs it resulted in. 
