%!TEX root = ../main.tex


\section{Factors Contributing to a Successful Course}
\label{section:whatworked}

Understanding and re-implementing the work of other researchers is not a trivial task, especially for first-year MSc students. There were several aspects of the setup that we believe were beneficial for the students, which we organize along three dimensions: 
\begin{enumerate*}[label=(\roman*)]
    \item general, 
    \item concerning FACT-AI, and 
    \item concerning reproducibility.
\end{enumerate*}
We believe each of these factors is important for a successful implementation of this course, or other similar courses. 

\subsection{General}

\subsubsection{Timing of the course}
It is important that students have prior knowledge of ML theory as well as some programming experience before completing a project-based course in groups. At \OurUniversity{}, the FACT-AI course takes place after students have completed 4 ML-focused courses (see Table~\ref{tab:msc_program}). 
We believe it is extremely important that students have access to adequate preparation, especially in terms of programming experience, before setting off to reproduce experiments from prominent AI papers. 
Without this prior knowledge, we believe such a project would not be feasible in the allotted time frame. 

\subsubsection{Regular contact with experienced TAs}
The TAs are there to help with two main components: 
\begin{enumerate*}[label=(\roman*)]
\item understanding the paper, and 
\item debugging the implementation process. 
\end{enumerate*}
In practice, we found that it is extremely important for the TAs to have excellent programming experience since this is the main aspect students need help with. 
%We found it even more beneficial if the TAs had taken the course themselves previously, so we plan to recruit future TAs from the pool of students that completed the course in the previous year. 
We also had a dedicated Slack workspace for the TAs and course instructors to keep in touch regularly. 

Since our course is only four weeks long, we found it was important for students to have regular contact with their TAs to ensure no one got stuck in the process. 
For the first (in-person) iteration of the course, groups had one-hour tutorials with their TAs twice per week, where all groups that were working on the same paper (and therefore had the same TA) were in the same tutorial. 
Since they were all working on the same paper, there were many overlapping questions, and students found it beneficial to be able to share their experiences with one another. 
For the second (online) iteration of the course, we thought it would be challenging to ensure each group got the attention they needed if everyone was in one large online tutorial, so the TAs met with each group separately for 30 minutes, twice per week. 

\subsubsection{Early feedback on the reports}
Approximately halfway through the course, we asked students to submit a draft report to their TAs in order to get feedback. We found this significantly increased the quality of the final reports. 

\subsection{Concerning FACT-AI}

\subsubsection{Emphasizing the technical perspective of FACT-AI}
Given that the FACT-AI course is situated in the context of a technical, research-oriented MSc, having students re-implement research papers from top AI conferences was an effective way to teach FACT-AI topics for our students. 
Teaching FACT-AI from a primarily technical perspective 
aligns well with what students expect from the MSc AI program at \OurUniversity{}.
Although we believe a technical focus makes sense for our MSc program, we also believe it is important to incorporate non-technical perspectives into the course -- see Section~\ref{section:non-technical}. 

\subsubsection{Creating resources for the FACT-AI community}
We believe a significant motivating factor for students was creating concrete output that extended beyond simply completing a project for a course: creating resources for the FACT community. 
In the 2019--2020 iteration, this was done by creating a public repository with the best FACT-AI algorithm implementations, as selected by the TAs. 
In the 2020--2021 iteration, this was done by publicly submitting their reproducibility reports about FACT-AI algorithms to the ML Reproducibility Challenge, where the accepted reports were published in the ReScience Journal. 
In the future, we plan to continue aligning our course with the ML Reproducibility Challenge since we found the process extremely beneficial for our students. 

\subsection{Concerning Reproducibility}

\subsubsection{Including extension as part of reproducibility}
If source code was already available for the paper -- which is fortunately becoming increasingly common for AI research papers -- we asked students to think about how to extend the paper since the implementation was already available. This resulted in some creative and interesting ideas in the reports, and we believe this is why our students performed well at the ML Reproducibility Challenge.

\subsubsection{Simple grading setup}
For a 4-week, project-based course, we found it was beneficial for students to focus on one main deliverable consisting of three components: 
\begin{enumerate*}[label=(\roman*)]
\item the reproducibility report, 
\item the associated code base, and
\item the group presentation. 
\end{enumerate*}
The report that students submitted for the course was the same one they submitted to the ML Reproducibility Challenge. This way, participating in the ML Reproducibility Challenge was not an extra task but rather an integral part of the course. 


\section{Areas of Improvement}
\label{section:whatdidnt}


Although we believe both iterations of the course went well, there are several aspects of the setup that we believe could use some improvement and other instructors should consider if they plan to implement a similar course. 

\subsection{General}

Given that this is the first time most students are formally submitting a paper, it is not surprising that there were some logistical issues. 
Some groups made minor mistakes such as forgetting to submit their work double-blind or slightly missing the submission deadline. 
We also had some groups who wrote the introduction sections of their papers as an introduction to the FACT-AI course, rather than an introduction to the topic they were working on. 
In future iterations, we will explicitly state the standard procedures of writing and submitting a paper and provide some examples. 

\subsection{Concerning FACT-AI}
\label{section:non-technical}

Although focusing primarily on the technical aspects of FACT-AI is an effective way to engage our technical students in socially-relevant AI problems, we also believe that they would benefit from additional non-technical perspectives on FACT-AI topics. 
In the future, we plan to include perspective from outside of computer science through 
\begin{enumerate*}[label=(\roman*)]
\item additional guest lectures, 
\item workshop sessions \citep{skirpan2018ethics,shenvalue2021}, and 
\item broader impact statements \citep{campbell2021_responsible} in the reproducibility reports. 
\end{enumerate*}

\subsection{Concerning Reproducibility}
In future iterations, we believe it would be useful to show students more examples of what a high-quality reproducibility paper looks like and explain in-depth why it is high-quality. 
These could be papers that were previously accepted to the ML Reproducibility Challenge, or papers from other reproducibility efforts outlined in Section~\ref{section:reproducibility}. 
We want the students to understand what makes a paper a good (reproducibility) paper, that is, it has a set of (reproducibility) claims, it argues for these claims, and shows evidence to support these claims.  