%!TEX root = ../main.tex

\section{Course Setup}
\label{section:coursesetup}

% The course is located right after the winter break of the second and last year of the Master in AI at \OurUniversity{}. 
% Thus, students can fully focus on it before starting to write their Master Thesis.
The FACT-AI course is organized around 
\begin{enumerate*}[label=(\roman*)]
    \item lectures, 
    \item paper discussions, and
    \item a group project. 
\end{enumerate*}
It has had two iterations so far: the 2019--2020 iteration was taught in person, while the 2020--2021 iteration was taught online due to the COVID-19 pandemic. 
In this section, we detail how we realized the learning objectives from Section~\ref{section:learning-objectives} and describe the challenges in adapting the course to an online format.

\subsection{Lectures}
To further the understanding of FACT-AI topics (LO1), we provide one general lecture for each of the 4 topics, along with a lecture specifically about reproducibility.
Lectures are an opportunity for students to familiarize themselves with algorithmic harm (LO2). Students are encouraged to ask questions that lead to discussions about potential harm done by applications of AI. 
This was more challenging in the second iteration of the course due to the online format, but we hope that facilitating such discussions will be more straightforward once we return to in-person classes. 

In addition to the general lectures, we also include some guest lectures. 
These are used to either discuss specific types of algorithmic harm (LO2), examine specific FACT-AI algorithms in depth (LO3), or expand on the non-technical aspects of FACT-AI. 
Some examples of guest lectures include a lecture on AI accountability from a legal perspective by an instructor from the law department of \OurUniversity{}, and a lecture by two former FACT-AI students who explained how they turned their group project into an ICML 2021 workshop paper \citep{neely2021order}.\footnote{This was later extended to a full paper at the International Conference on Hybrid Human-AI (HHAI 2022) \citep{neely2022song}.} 

\subsection{Paper Discussions}
The goal of the paper discussion sessions is for students to learn about prominent FACT-AI methods (LO3), and learn to think critically about the claims made in the papers we discuss (LO4). 
Students first read a seminal FACT-AI paper on their own while trying to answer the following questions: 
\begin{itemize}
\item What are the main claims of the paper?
\item What are the research questions?
\item Does the experimental setup make sense, given the research questions?
\item What are the answers to the research questions? Are these supported by experimental evidence?
\end{itemize}

\noindent%
Once students have read the papers, they participate in smaller discussion sessions with their peers about their answers to the questions above. 
After each discussion session, all the groups are brought back together for a ``dissection'' session, where an instructor goes over the same seminal paper, giving an overview of the papers' strengths and weaknesses. 
%
Each session was presented by a different instructor to show that there is no single way of examining a research paper, and that different researchers will bring different perspectives to their assessment of papers. 
The following papers were covered during the discussion sessions: 
\citet{hardt_equality_2016} on fairness; 
\citet{ribeiro-2016-should} on transparency; and 
\citet{Abadi_2016} on confidentiality.


\subsection{Group Project}
\label{section:assignment}

\subsubsection{Reproduction of a FACT-AI paper}
The purpose of the group project is to have students investigate the claims made by the authors of recent FACT-AI papers by diving into the details of the methods and their implementations.  
Using what they have learned from the paper discussion sessions, students work in groups to re-implement an existing FACT-AI algorithm from a top AI conference and re-run the experiments in the paper to determine the degree to which they are reproducible (LO4). 
If the code is already available, then they must extend the method in some way. 
The project consisted of three deliverables: 
\begin{enumerate*}[label=(\roman*)]
\item a reproducibility report, 
\item an associated code base, and 
\item a group presentation. 
\end{enumerate*}
%
In order to ensure the project is feasible, we select 10--15 papers in advance for groups to choose from. 
Our criteria for including papers is as follows:
\begin{itemize}
    \item The paper is on a FACT-AI topic. 
    \item At least one dataset in the paper is publicly available.
    \item Experiments can be run on a single GPU (which we provide access to).
    \item It is reasonable for a group of 3--4 MSc AI students to re-implement the paper within the timeframe of the course. In our case, students work on this project for one-month full-time. 
\end{itemize}

\noindent%
To ease the load for our teaching assistants (TAs), we have several groups working on the same paper. 
We assign papers to TAs based on their interests by asking them to rank the set of candidate papers in advance. 
We also encourage them to suggest alternative papers provided they fit the criteria. 
The TAs read the papers before the course starts in order to ensure they have a sufficient, in-depth understanding of the work such that they can guide students through the project. 
This also serves as an extra feasibility check, to ensure that the papers are indeed a good fit for our course.

Each group writes a report about their efforts following the structure of a standard research paper (i.e., introduction, methodology, experiments, results, conclusion). 
They also include aspects specific to reproducibility such as explaining the difficulties of implementing certain components, as well as describing any communication they had with the original authors.
In addition to the source code, students provide all results in a Jupyter notebook along with a file to install the required environment. 

\subsubsection{First Iteration: Contributing to an Open Source Repository}
In the 2019--2020 iteration of the course, we created a public repository on GitHub, which contains a selection of the implementations done by our students: \url{https://github.com/uva-fact-ai-course/uva-fact-ai-course}. 
The TAs who assisted with the course decided which implementations to include and cleaned up the code so it all fit into one cohesive repository. 
This had multiple motivations.
First, it taught students how to improve the reproducibility of their own work by releasing the code, while also giving them a sense of contributing to the open-source community. 
Second, a public repository can serve as a starting point for personal development in their future careers; companies often ask to see existing code or projects that prospective employees have worked on. 
Some students added the project to their CVs, while others wrote blog posts about their experiences,\footnote{\url{https://omarelb.github.io/self-explaining-neural-networks/}}  linking back to the repository.

\subsubsection{Second Iteration: The ML Reproducibility Challenge}
In the 2020--2021 iteration of the course, we formally participated in the annual ML Reproducibility Challenge \citep{paperswithcode2020} in order to expose our students to the peer-review process. 
This gave students something to strive towards and offered perspectives beyond simply getting a grade for the project. 
Most importantly, it gave them the opportunity to experience the full research pipeline: 
\begin{enumerate*}[label=(\roman*)]
	\item reading a technical paper, 
	\item understanding a paper's strength and weaknesses, 
	\item implementing (and perhaps also extending) the paper, 
	\item writing up the findings, 
	\item submitting to a venue with a deadline, 
	\item obtaining feedback, 
	\item writing a rebuttal, and
	\item receiving the official notification. 
\end{enumerate*}
To encourage students to formally submit to the ML Reproducibility Challenge, we offered a 5\% boost to their final grades if they submitted. 
Of the 32 groups in the FACT-AI course, 30 (94\%) groups submitted their reproducibility reports to the ML Reproducibility Challenge, of which 9 groups had their papers accepted.

\subsection{Online Course Format}
The second iteration of the course was taught in January 2021, when the COVID-19 pandemic forced us to move classes and interactions online. 
Students made use of various channels to communicate: WhatsApp, Discord, and Slack.  
Canvas was the primary mode of communication between the instructors and the students, allowing students to ask questions and instructors to communicate various announcements. 

Lectures were live, with frequent Q\&A breaks to stimulate interactivity. 
Paper discussion sessions were organized in different online meeting subrooms where students discussed the papers together.  
This proved to be a challenge: while some subrooms had productive discussions, others struggled to get the conversation going. 

The reproducibility project was more difficult to launch remotely. 
Since students had done online classes for their entire first semester, some struggled to find a group of fellow students to team up with, especially those coming from outside the MSc AI program. 
Overall, while we had various communication means, the lack of physical interaction due to COVID-19 slowed down our course organization. 
