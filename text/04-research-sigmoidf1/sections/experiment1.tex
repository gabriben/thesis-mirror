%!TEX root = ../main.tex

\section{Experiment 1: FOCUS vs. FT}
\label{section:experiment1}



We compare FOCUS to the Feature Tweaking (FT) method by \citet{tolomei_interpretable_2017} in terms of the evaluation metrics in Section~\ref{section:focus-evalmetrics}. 
We consider \numprint{36} experimental settings (\numprint{4} datasets $\times$ \numprint{3} tree-based models $\times$ \numprint{3} distance functions) when comparing FOCUS to FT. 
The results are listed in Table~\ref{table:distances}. 

\subsection{Baseline: Feature Tweaking}
\label{section:baselineft}
FT identifies the leaf nodes where the prediction of the leaf nodes do not match the original prediction $y_x$: it recognizes the set of leaves that if activated, $t_j(\bar{x}) = 1$, would change the prediction of a tree $\mathcal{T}$:
\begin{equation}
\mathcal{T}_\textit{change} = \left\{ j \mid j \in   \mathcal{T}_\textit{leaf} \land y_x \not = \arg \max_y T(y\mid j) \right\}.
\end{equation}
For every $\mathcal{T}$ in $f$, FT generates a perturbed example per node in $\mathcal{T}_\textit{change}$ so that it is activated with at least an $\epsilon$ difference per threshold, and then selects the most optimal example (i.e., the one closest to the original instance).
For every feature threshold $\theta_j$ involved, the corresponding feature is perturbed accordingly: $\bar{x}_{f_j} = \theta_j \pm \epsilon$.
The result is a perturbed example that was changed minimally to activate a leaf node in $\mathcal{T}_\textit{change}$. 
In our experiments, we test $\epsilon \in \{0.001, 0.005, 0.01, 0.1\}$, and choose the $\epsilon$ that minimizes the mean distance to the original input, while maximizing the number of counterfactual examples generated. 


The main problem with FT is that the perturbed examples are not necessarily counterfactual examples, since changing the prediction of a single tree $\mathcal{T}$ does not guarantee a change in the prediction of the full ensemble $f$.
Figure~\ref{fig:approxensemble} shows all three perturbed examples generated by FT for a single instance. 
In this case, none of the generated examples change the model prediction and therefore none are valid counterfactual examples. 

Figure~\ref{fig:approxensemble} shows how FOCUS and FT handle an adaptive boosting ensemble using a two-feature ensemble with three trees. 
On the left is the decision boundary for a standard tree ensemble; the middle visualizes the positive leaf nodes that form the decision boundary; on the right is the approximated loss $\widetilde{\mathcal{L}}_{pred}$ and its gradient w.r.t. $\bar{x}$.
The gradients push features close to thresholds harder and in the direction of the decision boundary if $\widetilde{\mathcal{L}}$ is convex. 


\subsection{Results}
In terms of $d_\mathit{mean}$, FOCUS outperforms FT in \numprint{20} settings while FT outperforms FOCUS in \numprint{8} settings. The difference in $d_\mathit{mean}$ is not significant in the remaining \numprint{8} settings. 
In general, FOCUS outperforms FT in settings using Euclidean and Cosine distance because in each iteration, FOCUS perturbs many of the features by a small amount. 
Since FT perturbs only the features associated with an individual leaf, we expected that it would perform better for Manhattan distance but our results show that this is not the case. 
There is no clear winner between FT and FOCUS for Manhattan distance. 

\begin{figure}[t]
\centering
\includegraphics[scale=0.23]{04-research-focus/figures/decision_example} 
\includegraphics[scale=0.23]{04-research-focus/figures/leaf_example} 
\includegraphics[scale=0.23]{04-research-focus/figures/approx_example}
\caption{
An example of how the FT baseline method (explained in Section~\ref{section:baselineft}) and our method handle an adaptive boosting ensemble with three trees.
Left: decision boundary of the ensemble.
Middle: three positive leaves that form the decision boundary, an example instance, and the perturbed examples suggested by \acs{FT}. 
Right: approximated loss $\widetilde{\mathcal{L}}_{pred}$ and its gradient w.r.t. $\bar{x}$. 
The \acs{FT} perturbed examples do not change the prediction of the forest, whereas the gradient of the differentiable approximation leads toward the true decision boundary.
}
\label{fig:approxensemble}
\end{figure}



\begin{landscape}
\begin{table}
\caption{Evaluation results for Experiment 1 comparing FOCUS and FT counterfactual examples. Significant improvements and losses over the baseline (FT) are denoted by \dubbelneer\ and \dubbelop, respectively ($p < 0.05$, two-tailed t-test,); 
\notsig{} denotes no significant difference;
\NoExample{} denotes settings where the baseline cannot find a counterfactual example for every instance.}
\input{04-research-focus/sections/widetable3}
\label{table:distances}
\end{table}
\end{landscape}


\noindent
We also see that FOCUS usually outperforms FT in settings using random forests and adaptive boosting, while the opposite is true for decision trees. 

Overall, we find that FOCUS is effective and efficient for finding counterfactual explanations for tree-based models.
Unlike the FT baseline, FOCUS finds valid counterfactual explanations for \emph{every} instance across all settings. 
In the majority of tested settings, FOCUS's explanations are substantial improvements in terms of distance to the original inputs, across all three metrics. 






