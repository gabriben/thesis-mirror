%!TEX root = ../main.tex

\section{Conclusion}
\label{section:focus-conclusion}
In this chapter, we propose an explanation method for tree-based classifiers, FOCUS, which casts the problem of finding counterfactual examples as a gradient-based optimization task and provides a differentiable approximation of tree-based models to be used in the optimization framework. 

Given an input instance $x$, FOCUS generates an optimal counterfactual example based on the minimal perturbation to the input instance $x$ which results in an alternative prediction from a model $f$. 
Unlike previous methods that assume the underlying classification model is differentiable, we propose a solution for when $f$ is a non-differentiable, tree-based model that provides a differentiable approximation of $f$, which can be used to find counterfactual examples using gradient-based optimization techniques.  

In the majority of experiments, examples generated by FOCUS are significantly closer to the original instances in terms of three different evaluation metrics compared to those generated by the baselines. 
FOCUS is able to generate valid counterfactual examples for all instances across all datasets, and the resulting explanations are flexible depending on the distance function. 


This answers \textbf{\ref{rq:focus}}: we can generate counterfactual explanations for tree-based models using gradient-based optimization if we include differentiable approximations of tree-based models within the optimization framework. 
In the following chapter, we will investigate how to extend our method to accommodate different types of data such as graphs. 
