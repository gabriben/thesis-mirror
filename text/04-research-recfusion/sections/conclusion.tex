%!TEX root = ../main.tex











\section{Conclusion}
\label{section:cfgnn-conclusion}
In this chapter, we propose CF-GNNExplainer, a method for generating counterfactual explanations for any GNN. Our simple and effective method is able to generate counterfactual explanations that are (i) minimal, both in terms of the absolute number of edges removed (explanation size), as well as the proportion of the \cgraph{} that is perturbed (sparsity), and (ii) accurate, in terms of removing edges that we know to be crucial for the initial predictions. 

We evaluate our method on three commonly used datasets for GNN explanation tasks and find that these results hold across all three datasets. 
We find that existing GNN XAI methods are not well-suited to solving the counterfactual explanation task, while CF-GNNExplainer is able to reliably produce minimal, accurate counterfactual explanations. 

This answers \textbf{\ref{rq:cf-gnn}}: we can generate counterfactual explanations for graph-based models by extending the problem formalization from Chapter~\ref{chapter:research-focus} to accommodate graph data. 
We do so by introducing a perturbation matrix that acts on the adjacency matrix to remove edges in the graph, then applying similar gradient-based optimization techniques as in Chapter~\ref{chapter:research-focus} for each instance in the dataset. 
In the following chapter, we will investigate how to generate explanations that are specific to a particular real-world use case and evaluate them on real users. 

